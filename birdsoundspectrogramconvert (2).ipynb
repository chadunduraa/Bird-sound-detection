{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FwmF5rSKMLYy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c65b323-e122-418d-a5aa-2ef8a74d0e9b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras import layers, models\n",
        "import numpy as np\n",
        "import librosa\n",
        "import librosa.display\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "yFFwtv_rMlwU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#this code\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "\n",
        "    # Load audio\n",
        "def generate_mel_spectrogram(audio_path, annotation_path, output_dir, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "    # Read annotations\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Process each annotation with label \"song\" or \"call\"\n",
        "    for annotation in annotations:\n",
        "        start_sec, end_sec, label = annotation.split()\n",
        "        start_sec, end_sec = map(float, (start_sec, end_sec))\n",
        "        if label in [\"song\", \"call\", \"drumming\", \"clapping\"]:\n",
        "            # Iterate through each second within the annotated range\n",
        "            for sec in np.arange(start_sec, end_sec + 1):\n",
        "                start_frame = int(sec * sr)\n",
        "                end_frame = int((sec + 1) * sr)\n",
        "\n",
        "                # Check if segment length is long enough for n_fft\n",
        "                if end_frame - start_frame >= n_fft:\n",
        "                    # Extract segment\n",
        "                    segment = y[start_frame:end_frame]\n",
        "\n",
        "                    # Compute mel spectrogram\n",
        "                    S = librosa.feature.melspectrogram(y=segment, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "                    S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "                    # Save spectrogram as .npy\n",
        "                    output_filename = f\"{label}_{sec}.npy\"\n",
        "                    np.save(os.path.join(output_dir, output_filename), S_db)\n",
        "\n",
        "def process_dataset(dataset_dir, output_dir):\n",
        "    for root, dirs, files in os.walk(dataset_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.mp3'):\n",
        "                audio_path = os.path.join(root, file)\n",
        "                annotation_path = os.path.join(root, file.replace('.mp3', '.txt'))\n",
        "                output_subdir = os.path.join(output_dir, os.path.basename(root))\n",
        "                os.makedirs(output_subdir, exist_ok=True)\n",
        "                generate_mel_spectrogram(audio_path, annotation_path, output_subdir)\n",
        "\n",
        "# Example usage\n",
        "dataset_dir = '/content/drive/My Drive/birdaudio/'\n",
        "output_dir = '/content/drive/My Drive/spectrogramnpy_main/'\n",
        "process_dataset(dataset_dir, output_dir)"
      ],
      "metadata": {
        "id": "vC0TfdogJET0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uv4FGydfQbaT"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}