{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5R_tYQvA4niv",
        "outputId": "c70f554e-ac8a-4172-cbc4-bb6f702794fd"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "!pip install pydub\n",
        "from pydub import AudioSegment\n",
        "\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "def concatenate_audio(audio_path, annotation_path, output_dir, sr=22050):\n",
        "    # Load audio\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "    # Read annotations\n",
        "    with open(annotation_path, 'r') as f:\n",
        "        annotations = f.readlines()\n",
        "\n",
        "    # Initialize concatenated audio\n",
        "    concatenated_audio = AudioSegment.silent(duration=0)\n",
        "\n",
        "    # Process each annotation with label \"song\" or \"call\"\n",
        "    for annotation in annotations:\n",
        "        start_sec, end_sec, label = annotation.split()\n",
        "        start_sec, end_sec = map(float, (start_sec, end_sec))\n",
        "        if label in [\"song\", \"call\", \"drumming\", \"clapping\"]:\n",
        "            # Convert start and end seconds to frames\n",
        "            start_frame = int(start_sec * sr)\n",
        "            end_frame = int(end_sec * sr)\n",
        "\n",
        "            # Extract segment\n",
        "            segment = y[start_frame:end_frame]\n",
        "\n",
        "            # Append segment to concatenated audio\n",
        "            segment = librosa.util.buf_to_float(segment)\n",
        "            segment_audio = AudioSegment(segment.tobytes(), frame_rate=sr, sample_width=segment.dtype.itemsize, channels=1)\n",
        "            concatenated_audio += segment_audio\n",
        "\n",
        "    # Save concatenated audio as .mp3\n",
        "    output_filename = os.path.basename(audio_path).replace('.mp3', '_concatenated.mp3')\n",
        "    output_path = os.path.join(output_dir, output_filename)\n",
        "    concatenated_audio.export(output_path, format=\"mp3\")\n",
        "\n",
        "def process_dataset(dataset_dir, output_dir):\n",
        "    for root, dirs, files in os.walk(dataset_dir):\n",
        "        for file in files:\n",
        "            if file.endswith('.mp3'):\n",
        "                audio_path = os.path.join(root, file)\n",
        "                annotation_path = os.path.join(root, file.replace('.mp3', '.txt'))\n",
        "                output_subdir = os.path.join(output_dir, os.path.relpath(root, dataset_dir))\n",
        "                os.makedirs(output_subdir, exist_ok=True)\n",
        "                concatenate_audio(audio_path, annotation_path, output_subdir)\n",
        "\n",
        "# Example usage\n",
        "dataset_dir = '/content/drive/My Drive/birdaudio/'\n",
        "output_dir = '/content/drive/My Drive/concatenated_audio/'\n",
        "process_dataset(dataset_dir, output_dir)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIVmJmcE1rA5",
        "outputId": "e4a41f20-e617-4d7c-bd35-67093142e78d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pydub\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Installing collected packages: pydub\n",
            "Successfully installed pydub-0.25.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "\n",
        "class_labels = [\n",
        "    'Acrocephalus melanopogon','Acrocephalus melanopogon','Acrocephalus scirpaceus',  'Alcedo atthis','Anas platyrhynchos','Anas strepera','Ardea purpurea','Botaurus stellaris',  'Charadrius alexandrinus',\n",
        "     'Ciconia ciconia','Circus aeruginosus', 'Coracias garrulus', 'Dendrocopos minor', 'Fulica atra','Gallinula chloropus','Himantopus himantopus','Ixobrychus minutus',\n",
        "    'Motacilla flava','Porphyrio porphyrio','Tachybaptus ruficollis'\n",
        "]\n",
        "\n",
        "def load_mel_spectrogram(file_path):\n",
        "    return np.load(file_path)\n",
        "\n",
        "# Function to preprocess data for prediction\n",
        "def preprocess_data(spectrogram, target_size=(128, 128)):\n",
        "    # Resize spectrogram\n",
        "    resized_spectrogram = cv2.resize(spectrogram, target_size)\n",
        "    # Add extra dimensions to match model input shape\n",
        "    resized_spectrogram = np.expand_dims(resized_spectrogram, axis=0)\n",
        "    resized_spectrogram = np.expand_dims(resized_spectrogram, axis=-1)\n",
        "    return resized_spectrogram\n",
        "\n",
        "# Function to make predictions\n",
        "def predict(model, spectrogram):\n",
        "    # Preprocess the spectrogram\n",
        "    preprocessed_spectrogram = preprocess_data(spectrogram)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(preprocessed_spectrogram)\n",
        "    return prediction\n",
        "\n",
        "def generate_mel_spectrogram(audio_path, output_dir, model, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    # Load audio\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "    # Calculate total number of seconds\n",
        "    total_seconds = len(y) // sr\n",
        "\n",
        "    # Process each second of the audio\n",
        "    for sec in range(total_seconds):\n",
        "        start_frame = int(sec * sr)\n",
        "        end_frame = int((sec + 1) * sr)\n",
        "\n",
        "        # Check if segment length is long enough for n_fft\n",
        "        if end_frame - start_frame >= n_fft:\n",
        "            # Extract segment\n",
        "            segment = y[start_frame:end_frame]\n",
        "\n",
        "            # Compute mel spectrogram\n",
        "            S = librosa.feature.melspectrogram(y=segment, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "            S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "            # Save spectrogram as .npy\n",
        "            output_filename = f\"{os.path.splitext(os.path.basename(audio_path))[0]}_{sec}.npy\"\n",
        "            np.save(os.path.join(output_dir, output_filename), S_db)\n",
        "\n",
        "            # Load the saved spectrogram\n",
        "            mel_spectrogram = load_mel_spectrogram(os.path.join(output_dir, output_filename))\n",
        "\n",
        "            # Make predictions\n",
        "            prediction = predict(model, mel_spectrogram)\n",
        "            predicted_label = np.argmax(prediction)\n",
        "            predicted_class = class_labels[predicted_label]\n",
        "\n",
        "            print(f\"Predicted label for {output_filename}: {predicted_class}\")\n",
        "\n",
        "def process_single_audio(audio_path, output_dir, model):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Generate mel spectrograms for the single audio file\n",
        "    generate_mel_spectrogram(audio_path, output_dir, model)\n",
        "\n",
        "# Load your trained model\n",
        "model_path = '/content/drive/My Drive/saved_models/trained_model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Example usage\n",
        "dataset_dir = '/content/drive/My Drive/birdaudio/Ardea purpurea/XC485377.mp3'\n",
        "output_dir = '/content/drive/My Drive/predictionspectrogram/XC485377/'\n",
        "process_single_audio(dataset_dir, output_dir, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "puoUqqk2kxOt",
        "outputId": "238476e8-ae0f-4cec-af81-9fb846d3716c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 120ms/step\n",
            "Predicted label for XC485377_0.npy: Ixobrychus minutus\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Predicted label for XC485377_1.npy: Charadrius alexandrinus\n",
            "1/1 [==============================] - 0s 38ms/step\n",
            "Predicted label for XC485377_2.npy: Alcedo atthis\n",
            "1/1 [==============================] - 0s 34ms/step\n",
            "Predicted label for XC485377_3.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 40ms/step\n",
            "Predicted label for XC485377_4.npy: Ixobrychus minutus\n",
            "1/1 [==============================] - 0s 62ms/step\n",
            "Predicted label for XC485377_5.npy: Circus aeruginosus\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicted label for XC485377_6.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Predicted label for XC485377_7.npy: Acrocephalus melanopogon\n",
            "1/1 [==============================] - 0s 54ms/step\n",
            "Predicted label for XC485377_8.npy: Gallinula chloropus\n",
            "1/1 [==============================] - 0s 49ms/step\n",
            "Predicted label for XC485377_9.npy: Motacilla flava\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "Predicted label for XC485377_10.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Predicted label for XC485377_11.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Predicted label for XC485377_12.npy: Acrocephalus melanopogon\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Predicted label for XC485377_13.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 53ms/step\n",
            "Predicted label for XC485377_14.npy: Ixobrychus minutus\n",
            "1/1 [==============================] - 0s 57ms/step\n",
            "Predicted label for XC485377_15.npy: Acrocephalus melanopogon\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Predicted label for XC485377_16.npy: Tachybaptus ruficollis\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "Predicted label for XC485377_17.npy: Gallinula chloropus\n",
            "1/1 [==============================] - 0s 52ms/step\n",
            "Predicted label for XC485377_18.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Predicted label for XC485377_19.npy: Acrocephalus melanopogon\n",
            "1/1 [==============================] - 0s 59ms/step\n",
            "Predicted label for XC485377_20.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 58ms/step\n",
            "Predicted label for XC485377_21.npy: Ardea purpurea\n",
            "1/1 [==============================] - 0s 35ms/step\n",
            "Predicted label for XC485377_22.npy: Acrocephalus scirpaceus\n",
            "1/1 [==============================] - 0s 39ms/step\n",
            "Predicted label for XC485377_23.npy: Coracias garrulus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import librosa\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import load_model\n",
        "import cv2\n",
        "from collections import Counter\n",
        "\n",
        "class_labels = [\n",
        "    'Acrocephalus melanopogon', 'Acrocephalus melanopogon', 'Acrocephalus scirpaceus', 'Alcedo atthis',\n",
        "    'Anas platyrhynchos', 'Anas strepera', 'Ardea purpurea', 'Botaurus stellaris', 'Charadrius alexandrinus',\n",
        "    'Ciconia ciconia', 'Circus aeruginosus', 'Coracias garrulus', 'Dendrocopos minor', 'Fulica atra',\n",
        "    'Gallinula chloropus', 'Himantopus himantopus', 'Ixobrychus minutus', 'Motacilla flava', 'Porphyrio porphyrio',\n",
        "    'Tachybaptus ruficollis'\n",
        "]\n",
        "\n",
        "def load_mel_spectrogram(file_path):\n",
        "    return np.load(file_path)\n",
        "\n",
        "# Function to preprocess data for prediction\n",
        "def preprocess_data(spectrogram, target_size=(128, 128)):\n",
        "    # Resize spectrogram\n",
        "    resized_spectrogram = cv2.resize(spectrogram, target_size)\n",
        "    # Add extra dimensions to match model input shape\n",
        "    resized_spectrogram = np.expand_dims(resized_spectrogram, axis=0)\n",
        "    resized_spectrogram = np.expand_dims(resized_spectrogram, axis=-1)\n",
        "    return resized_spectrogram\n",
        "\n",
        "# Function to make predictions\n",
        "def predict(model, spectrogram):\n",
        "    # Preprocess the spectrogram\n",
        "    preprocessed_spectrogram = preprocess_data(spectrogram)\n",
        "    # Make prediction\n",
        "    prediction = model.predict(preprocessed_spectrogram)\n",
        "    return prediction\n",
        "\n",
        "def generate_mel_spectrogram(audio_path, output_dir, model, sr=22050, n_fft=2048, hop_length=512, n_mels=128):\n",
        "    # Load audio\n",
        "    y, sr = librosa.load(audio_path, sr=sr)\n",
        "\n",
        "    # Calculate total number of seconds\n",
        "    total_seconds = len(y) // sr\n",
        "\n",
        "    # Process each second of the audio\n",
        "    for sec in range(total_seconds):\n",
        "        start_frame = int(sec * sr)\n",
        "        end_frame = int((sec + 1) * sr)\n",
        "\n",
        "        # Check if segment length is long enough for n_fft\n",
        "        if end_frame - start_frame >= n_fft:\n",
        "            # Extract segment\n",
        "            segment = y[start_frame:end_frame]\n",
        "\n",
        "            # Compute mel spectrogram\n",
        "            S = librosa.feature.melspectrogram(y=segment, sr=sr, n_fft=n_fft, hop_length=hop_length, n_mels=n_mels)\n",
        "            S_db = librosa.power_to_db(S, ref=np.max)\n",
        "\n",
        "            # Save spectrogram as .npy\n",
        "            output_filename = f\"{os.path.splitext(os.path.basename(audio_path))[0]}_{sec}.npy\"\n",
        "            np.save(os.path.join(output_dir, output_filename), S_db)\n",
        "\n",
        "            # Load the saved spectrogram\n",
        "            mel_spectrogram = load_mel_spectrogram(os.path.join(output_dir, output_filename))\n",
        "\n",
        "            # Make predictions\n",
        "            prediction = predict(model, mel_spectrogram)\n",
        "            predicted_label = np.argmax(prediction)\n",
        "            predicted_class = class_labels[predicted_label]\n",
        "\n",
        "\n",
        "\n",
        "def process_single_audio(audio_path, output_dir, model):\n",
        "    # Create output directory if it doesn't exist\n",
        "    os.makedirs(output_dir, exist_ok=True)\n",
        "\n",
        "    # Initialize dictionary to store predictions for each second\n",
        "    predictions = {}\n",
        "\n",
        "    # Generate mel spectrograms for the single audio file\n",
        "    generate_mel_spectrogram(audio_path, output_dir, model)\n",
        "\n",
        "    # Iterate through generated spectrograms and aggregate predictions\n",
        "    for file in os.listdir(output_dir):\n",
        "        if file.endswith('.npy'):\n",
        "            mel_spectrogram = load_mel_spectrogram(os.path.join(output_dir, file))\n",
        "            prediction = predict(model, mel_spectrogram)\n",
        "            predicted_label_index = np.argmax(prediction)\n",
        "            predicted_label = class_labels[predicted_label_index]\n",
        "\n",
        "            # Update predictions dictionary\n",
        "            predictions[file] = predicted_label\n",
        "\n",
        "    # Count occurrences of each predicted label\n",
        "    label_counts = Counter(predictions.values())\n",
        "\n",
        "    # Determine the most predicted label\n",
        "    final_prediction = max(label_counts, key=label_counts.get)\n",
        "\n",
        "    print(f\"Final predicted label for {audio_path}: {final_prediction}\")\n",
        "\n",
        "# Load your trained model\n",
        "model_path = '/content/drive/My Drive/saved_models/trained_model.h5'\n",
        "model = load_model(model_path)\n",
        "\n",
        "# Example usage\n",
        "dataset_dir = '/content/XC521814 (1).mp3'\n",
        "output_dir = '/content/drive/My Drive/predictionspectrogram/XC521814/'\n",
        "process_single_audio(dataset_dir, output_dir, model)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V1XIV95RzVaV",
        "outputId": "48cea037-f1f0-4b44-b219-48e0b48e557a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 124ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 60ms/step\n",
            "1/1 [==============================] - 0s 45ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 26ms/step\n",
            "1/1 [==============================] - 0s 68ms/step\n",
            "1/1 [==============================] - 0s 128ms/step\n",
            "1/1 [==============================] - 0s 56ms/step\n",
            "1/1 [==============================] - 0s 24ms/step\n",
            "1/1 [==============================] - 0s 29ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 32ms/step\n",
            "1/1 [==============================] - 0s 27ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 37ms/step\n",
            "1/1 [==============================] - 0s 36ms/step\n",
            "1/1 [==============================] - 0s 28ms/step\n",
            "1/1 [==============================] - 0s 30ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 17ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 19ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 21ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "1/1 [==============================] - 0s 16ms/step\n",
            "Final predicted label for /content/XC521814 (1).mp3: Porphyrio porphyrio\n"
          ]
        }
      ]
    }
  ]
}